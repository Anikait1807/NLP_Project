{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11406930,"sourceType":"datasetVersion","datasetId":7145328}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install evaluate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T15:44:47.547905Z","iopub.execute_input":"2025-04-15T15:44:47.548184Z","iopub.status.idle":"2025-04-15T15:44:50.592132Z","shell.execute_reply.started":"2025-04-15T15:44:47.548157Z","shell.execute_reply":"2025-04-15T15:44:50.591186Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T15:44:54.175101Z","iopub.execute_input":"2025-04-15T15:44:54.175687Z","iopub.status.idle":"2025-04-15T15:44:57.453130Z","shell.execute_reply.started":"2025-04-15T15:44:54.175657Z","shell.execute_reply":"2025-04-15T15:44:57.452130Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python\n# R3-QuARC+ : Memory-Efficient Reinforcement Learningâ€“Enhanced QA (Counterspeech) Model\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\nimport evaluate\nfrom datasets import Features, Value, load_dataset, concatenate_datasets, ClassLabel\n\n# Check device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# -------------------------------\n# 1. Load and Combine Data\n# -------------------------------\nexpected_features = Features({\n    \"hatespeech\": Value(\"string\"),\n    \"csType\": Value(\"string\"),\n    \"counterspeech\": Value(\"string\"),\n    \"Suggest\": Value(\"string\"),\n    \"Relevance\": Value(\"float64\"),\n    \"Aggressive\": Value(\"float64\"),\n    \"Complexity\": Value(\"float64\"),\n    \"Comments\": Value(\"float64\"),\n    \"source\": Value(\"string\"),\n    \"claim\": Value(\"string\"),\n    \"centralTopic\": Value(\"string\"),\n    \"speakerIntent\": Value(\"string\"),\n    \"targetGroup\": Value(\"string\"),\n    \"relevantPowerDynamics\": Value(\"string\"),\n    \"hatespeechImplication\": Value(\"string\"),\n    \"targetGroupEmotionalReaction\": Value(\"string\"),\n    \"targetGroupCognitiveReaction\": Value(\"string\"),\n    \"hatespeechOffensiveness\": Value(\"string\"),\n    \"id\": Value(\"int64\"),\n    \"is_high_quality\": Value(\"string\"),\n    \"hs_id\": Value(\"int64\"),\n    \"hatespeechTarget\": Value(\"string\"),\n    \"powerDynamics\": Value(\"string\"),\n    \"prompt_offensiveness\": Value(\"string\"),\n    \"prompt_target_group\": Value(\"string\"),\n    \"prompt_speaker_intent\": Value(\"string\"),\n    \"prompt_power_dynamics\": Value(\"string\"),\n    \"prompt_implication\": Value(\"string\"),\n    \"prompt_emotional_reaction\": Value(\"string\"),\n    \"prompt_cognitive_reaction\": Value(\"string\"),\n    \"prompt_cs_generation\": Value(\"string\")\n})\n\ndata_files = {\n    \"train\": \"/kaggle/input/nlp-midsem-novelty/train.csv\",\n    \"validation\": \"/kaggle/input/nlp-midsem-novelty/validation.csv\",\n    \"test\": \"/kaggle/input/nlp-midsem-novelty/test.csv\"\n}\n\nraw_datasets = load_dataset(\"csv\", data_files=data_files, features=expected_features)\n\n# Combine and shuffle\ncombined_ds = concatenate_datasets([\n    raw_datasets[\"train\"],\n    raw_datasets[\"validation\"],\n    raw_datasets[\"test\"]\n])\ncombined_ds = combined_ds.shuffle(seed=42)\n\n# -------------------------------\n# 2. Cast and Stratified Split\n# -------------------------------\nis_high_quality_label = ClassLabel(names=[\"no\", \"yes\"])\ncombined_ds = combined_ds.cast_column(\"is_high_quality\", is_high_quality_label)\n\nsplit1 = combined_ds.train_test_split(test_size=0.4, stratify_by_column=\"is_high_quality\", seed=42)\nnew_train = split1[\"train\"]\nsplit2 = split1[\"test\"].train_test_split(test_size=0.5, stratify_by_column=\"is_high_quality\", seed=42)\nnew_val = split2[\"train\"]\nnew_test = split2[\"test\"]\n\nraw_train = new_train\nraw_val = new_val\nraw_test = new_test\n\nprint(\"New Train distribution:\", raw_train.features[\"is_high_quality\"])\nprint(\"New Val distribution:\", raw_val.features[\"is_high_quality\"])\nprint(\"New Test distribution:\", raw_test.features[\"is_high_quality\"])\n\n# -------------------------------\n# 3. Initialize Tokenizers and Models (Lighter Models)\n# -------------------------------\n# Using t5-small for the actor reduces memory footprint.\nactor_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\nactor_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\").to(device)\n\n# Retain a lightweight critic.\ncritic_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\ncritic_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2).to(device)\n\nmax_seq_len = 128  # Reduce sequence length for memory savings\n\n# -------------------------------\n# 4. Define Helper Functions\n# -------------------------------\ndef build_rationale(imp, tg, pd, off):\n    rationale_parts = []\n    if imp:\n        text = str(imp).strip().strip('\"')\n        if not text.endswith(('.', '?', '!', '\"', \"'\")):\n            text = text.rstrip() + \".\"\n        rationale_parts.append(text)\n    if tg:\n        tg_text = str(tg).strip().strip('\"')\n        pd_text = str(pd).strip().strip('\"') if pd else \"\"\n        sentence = f\"It targets {tg_text}, reflecting {pd_text}.\" if pd_text else f\"It targets {tg_text}.\"\n        rationale_parts.append(sentence)\n    if off:\n        off_text = str(off).strip().strip('\"')\n        if not off_text.endswith(('.', '?', '!', '\"', \"'\")):\n            off_text = off_text.rstrip() + \".\"\n        if off_text and off_text[0].islower():\n            off_text = off_text.capitalize()\n        off_sentence = f\"This is {off_text}\" if not off_text.startswith(\"It is\") else off_text\n        if not off_sentence.endswith('.'):\n            off_sentence += '.'\n        rationale_parts.append(off_sentence)\n    return \" \".join(rationale_parts)\n\ndef prepare_actor(example):\n    hs = str(example.get(\"hatespeech\", \"\"))\n    cs_type = str(example.get(\"csType\", \"\"))\n    cs = str(example.get(\"counterspeech\", \"\"))\n    imp = example.get(\"hatespeechImplication\", \"\") or \"\"\n    tg = example.get(\"targetGroup\", \"\") or \"\"\n    pd = example.get(\"relevantPowerDynamics\", \"\") or \"\"\n    off = example.get(\"hatespeechOffensiveness\", \"\") or \"\"\n    input_text = f\"{cs_type}: {hs}\"\n    output_text = cs.strip()\n    if output_text and output_text[-1] not in \".!?\\\"'\":\n        output_text += \".\"\n    rationale_text = build_rationale(imp, tg, pd, off)\n    if rationale_text:\n        output_text += f\" Rationale: {rationale_text.strip()}\"\n        if output_text and output_text[-1] not in \".!?\\\"'\":\n            output_text += \".\"\n    model_inputs = actor_tokenizer(input_text, max_length=max_seq_len, truncation=True, padding=\"max_length\")\n    with actor_tokenizer.as_target_tokenizer():\n        labels = actor_tokenizer(output_text, max_length=max_seq_len, truncation=True, padding=\"max_length\")[\"input_ids\"]\n    labels = [l if l != actor_tokenizer.pad_token_id else -100 for l in labels]\n    return {\n        \"input_ids\": model_inputs.get(\"input_ids\", []),\n        \"attention_mask\": model_inputs.get(\"attention_mask\", []),\n        \"labels\": labels\n    }\n\ndef prepare_critic(example):\n    hs = str(example.get(\"hatespeech\", \"\"))\n    cs = str(example.get(\"counterspeech\", \"\"))\n    encodings = critic_tokenizer(hs, cs, max_length=max_seq_len, truncation=True, padding=\"max_length\")\n    label = example[\"is_high_quality\"]\n    return {**encodings, \"label\": label}\n\n# -------------------------------\n# 5. Prepare Datasets and Set Format\n# -------------------------------\nactor_train_ds = raw_train.map(prepare_actor, batched=False, remove_columns=raw_train.column_names)\nactor_val_ds   = raw_val.map(prepare_actor, batched=False, remove_columns=raw_val.column_names)\nactor_test_ds  = raw_test.map(prepare_actor, batched=False, remove_columns=raw_test.column_names)\n\ncritic_train_ds = raw_train.map(prepare_critic, batched=False, remove_columns=raw_train.column_names)\ncritic_val_ds   = raw_val.map(prepare_critic, batched=False, remove_columns=raw_val.column_names)\n\nprint(\"Actor Train Columns:\", actor_train_ds.column_names)\nprint(\"Actor Val Columns:\", actor_val_ds.column_names)\n\nactor_train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nactor_val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nactor_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ncritic_train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ncritic_val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# -------------------------------\n# 6. Create DataLoaders\n# -------------------------------\nbatch_size = 8\nactor_train_loader = DataLoader(actor_train_ds, batch_size=batch_size, shuffle=True)\nactor_val_loader = DataLoader(actor_val_ds, batch_size=batch_size)\ncritic_train_loader = DataLoader(critic_train_ds, batch_size=8, shuffle=True)\ncritic_val_loader = DataLoader(critic_val_ds, batch_size=8)\n\n# -------------------------------\n# 7. Initialize Optimizers\n# -------------------------------\nactor_optimizer = torch.optim.Adam(actor_model.parameters(), lr=5e-5)\ncritic_optimizer = torch.optim.Adam(critic_model.parameters(), lr=1e-5)\n\n# -------------------------------\n# 8. Supervised Training for Critic\n# -------------------------------\nprint(\"Training critic (quality classifier)...\")\nepochs_critic = 2\ncritic_model.train()\nfor epoch in range(epochs_critic):\n    total_loss = 0.0\n    for batch in critic_train_loader:\n        critic_optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attn = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n        outputs = critic_model(input_ids=input_ids, attention_mask=attn, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        critic_optimizer.step()\n        total_loss += loss.item()\n    avg_loss = total_loss / len(critic_train_loader)\n    print(f\"[Critic] Epoch {epoch+1}/{epochs_critic} - Average Loss: {avg_loss:.4f}\")\n\n# Evaluate critic on validation set\ncritic_model.eval()\ncorrect = 0\ntotal = 0\nfor batch in critic_val_loader:\n    input_ids = batch[\"input_ids\"].to(device)\n    attn = batch[\"attention_mask\"].to(device)\n    labels = batch[\"label\"].to(device)\n    with torch.no_grad():\n        logits = critic_model(input_ids=input_ids, attention_mask=attn).logits\n        preds = logits.argmax(dim=-1)\n    correct += (preds == labels).sum().item()\n    total += labels.size(0)\nval_acc = correct / total if total > 0 else 0\nprint(f\"[Critic] Validation Accuracy: {val_acc*100:.2f}%\")\n\n# -------------------------------\n# 9. Supervised Training for Actor\n# -------------------------------\nprint(\"\\nTraining actor model (supervised fine-tuning on reference counterspeech)...\")\nepochs_actor_sup = 2\nactor_model.train()\nrouge_metric = evaluate.load(\"rouge\")\nfor epoch in range(epochs_actor_sup):\n    total_loss = 0.0\n    for batch in actor_train_loader:\n        actor_optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attn = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        outputs = actor_model(input_ids=input_ids, attention_mask=attn, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        actor_optimizer.step()\n        total_loss += loss.item()\n    avg_loss = total_loss / len(actor_train_loader)\n    print(f\"[Actor Sup] Epoch {epoch+1}/{epochs_actor_sup} - Average Loss: {avg_loss:.4f}\")\n    \n    # Evaluate on validation after each epoch\n    actor_model.eval()\n    val_preds = []\n    val_refs = []\n    for batch in actor_val_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attn = batch[\"attention_mask\"].to(device)\n        with torch.no_grad():\n            gen_outputs = actor_model.generate(\n                input_ids=input_ids, \n                attention_mask=attn,\n                max_length=128, \n                num_beams=4, \n                num_return_sequences=1\n            )\n        for i, output_ids in enumerate(gen_outputs):\n            text = actor_tokenizer.decode(output_ids, skip_special_tokens=True)\n            if \"Rationale:\" in text:\n                text = text.split(\"Rationale:\")[0].strip()\n            val_preds.append(text)\n            ref_cs = actor_tokenizer.decode(\n                batch[\"labels\"][i][batch[\"labels\"][i] != -100],\n                skip_special_tokens=True\n            )\n            if \"Rationale:\" in ref_cs:\n                ref_cs = ref_cs.split(\"Rationale:\")[0].strip()\n            val_refs.append(ref_cs)\n    rouge_scores = rouge_metric.compute(\n        predictions=[p.strip() for p in val_preds],\n        references=[r.strip() for r in val_refs],\n        use_stemmer=True\n    )\n    print(f\"[Actor Sup] Epoch {epoch+1} Validation Metrics:\")\n    for key, value in rouge_scores.items():\n        if isinstance(value, dict) and \"mid\" in value:\n            score = value[\"mid\"].fmeasure * 100\n        else:\n            score = value * 100\n        print(f\"  {key}: {score:.2f}\")\n    actor_model.train()\n\n# -------------------------------\n# 10. Reinforcement Learning Phase (Actor-Critic with Mixed Precision)\n# -------------------------------\nprint(\"\\nStarting reinforcement learning refinement...\")\nrl_epochs = 2\nnum_candidates = 2  # Reduced candidate count\nrl_batch_size = 8   # Reduced batch size for RL loop\n\n# Set up automatic mixed precision (AMP)\nscaler = torch.cuda.amp.GradScaler()\n\nactor_rl_optimizer = torch.optim.Adam(actor_model.parameters(), lr=1e-5)\nactor_model.train()\ncritic_model.eval()  # Freeze critic during RL\n\n# For RL, reduce memory by using only needed columns from raw_train.\nrl_columns = [\"hatespeech\", \"csType\", \"counterspeech\", \"is_high_quality\"]\nraw_train_for_rl = raw_train.remove_columns(\n    [col for col in raw_train.column_names if col not in rl_columns]\n)\ntrain_loader_full = DataLoader(raw_train_for_rl, batch_size=rl_batch_size, shuffle=True)\n\nfor epoch in range(rl_epochs):\n    epoch_loss = 0.0\n    count = 0\n    for batch in train_loader_full:\n        hs_list = [str(x) for x in batch[\"hatespeech\"]]\n        cs_type_list = [str(x) for x in batch[\"csType\"]]\n        input_texts = [f\"{cs_type}: {hs}\" for cs_type, hs in zip(cs_type_list, hs_list)]\n        enc = actor_tokenizer(\n            input_texts,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=128\n        )\n        input_ids = enc[\"input_ids\"].to(device)\n        attn = enc[\"attention_mask\"].to(device)\n\n        with torch.no_grad():\n            gen_outputs = actor_model.generate(\n                input_ids=input_ids,\n                attention_mask=attn,\n                max_length=128,\n                do_sample=True,\n                top_p=0.9,\n                top_k=50,\n                num_return_sequences=num_candidates\n            )\n        gen_outputs = gen_outputs.cpu()\n\n        all_hs = []\n        all_cs_gen = []\n        for i, output_ids in enumerate(gen_outputs):\n            input_index = i // num_candidates\n            hs_text = hs_list[input_index]\n            output_text = actor_tokenizer.decode(output_ids, skip_special_tokens=True)\n            if \"Rationale:\" in output_text:\n                output_text = output_text.split(\"Rationale:\")[0].strip()\n            cs_text = output_text if output_text else \" \"\n            all_hs.append(hs_text)\n            all_cs_gen.append(cs_text)\n\n        critic_enc = critic_tokenizer(\n            all_hs,\n            all_cs_gen,\n            return_tensors=\"pt\",\n            truncation=True,\n            padding=True,\n            max_length=128\n        )\n        critic_in_ids = critic_enc[\"input_ids\"].to(device)\n        critic_attn = critic_enc[\"attention_mask\"].to(device)\n\n        with torch.no_grad():\n            logits = critic_model(critic_in_ids, attention_mask=critic_attn).logits\n            probs = torch.softmax(logits, dim=-1)\n            high_quality_probs = probs[:, 1]\n\n        repeat_input_ids = input_ids.repeat_interleave(num_candidates, dim=0)\n        repeat_attn = attn.repeat_interleave(num_candidates, dim=0)\n\n        labels_gen = gen_outputs.clone()\n        labels_gen[labels_gen == actor_tokenizer.pad_token_id] = -100\n        labels_gen = labels_gen.to(device)\n\n        with torch.cuda.amp.autocast():\n            actor_outputs = actor_model(\n                input_ids=repeat_input_ids,\n                attention_mask=repeat_attn,\n                labels=labels_gen\n            )\n            logits_seq = actor_outputs.logits\n            vocab_size = logits_seq.size(-1)\n            logits_flat = logits_seq.view(-1, vocab_size)\n            labels_flat = labels_gen.view(-1)\n            token_loss = F.cross_entropy(\n                logits_flat,\n                labels_flat,\n                reduction='none',\n                ignore_index=-100\n            )\n            token_loss = token_loss.view(len(gen_outputs), -1)\n            seq_nll = token_loss.sum(dim=1)\n            rewards = high_quality_probs.detach().cpu().view(-1)\n            seq_nll = seq_nll.to(device)\n\n            policy_loss = torch.tensor(0.0, device=device)\n            for bi in range(len(hs_list)):\n                start = bi * num_candidates\n                end = start + num_candidates\n                group_rewards = rewards[start:end]\n                group_nll = seq_nll[start:end]\n                baseline = group_rewards.mean()\n                group_loss = (baseline - group_rewards.to(device)) * group_nll\n                policy_loss += group_loss.sum()\n            policy_loss = policy_loss / (len(hs_list) * num_candidates)\n\n        scaler.scale(policy_loss).backward()\n        scaler.step(actor_rl_optimizer)\n        scaler.update()\n        epoch_loss += policy_loss.item()\n        count += 1\n\n    avg_epoch_loss = epoch_loss / max(count, 1)\n    print(f\"[RL] Epoch {epoch+1}/{rl_epochs} - Average Policy Loss: {avg_epoch_loss:.4f}\")\n\n    # Evaluate RL performance on validation after each RL epoch\n    actor_model.eval()\n    val_preds = []\n    val_refs = []\n    hq_scores = []\n    for batch in actor_val_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attn = batch[\"attention_mask\"].to(device)\n        with torch.no_grad():\n            gen_outputs = actor_model.generate(\n                input_ids=input_ids,\n                attention_mask=attn,\n                max_length=128,\n                num_beams=4,\n                num_return_sequences=1\n            )\n        for i, output_ids in enumerate(gen_outputs):\n            gen_text = actor_tokenizer.decode(output_ids, skip_special_tokens=True)\n            cs_text = gen_text.split(\"Rationale:\")[0].strip() if \"Rationale:\" in gen_text else gen_text\n            val_preds.append(cs_text)\n            ref_text = actor_tokenizer.decode(\n                batch[\"labels\"][i][batch[\"labels\"][i] != -100],\n                skip_special_tokens=True\n            )\n            ref_text = ref_text.split(\"Rationale:\")[0].strip() if \"Rationale:\" in ref_text else ref_text\n            val_refs.append(ref_text)\n            hs_text = actor_tokenizer.decode(batch[\"input_ids\"][i], skip_special_tokens=True)\n            if \": \" in hs_text:\n                _, hs_only = hs_text.split(\": \", 1)\n            else:\n                hs_only = hs_text\n            with torch.no_grad():\n                enc = critic_tokenizer(\n                    hs_only,\n                    cs_text,\n                    truncation=True,\n                    padding=True,\n                    return_tensors=\"pt\",\n                    max_length=128\n                )\n                enc_input_ids = enc[\"input_ids\"].to(device)\n                enc_attn = enc[\"attention_mask\"].to(device)\n                logits = critic_model(enc_input_ids, attention_mask=enc_attn).logits\n                prob = F.softmax(logits, dim=-1)[0, 1].item()\n            hq_scores.append(prob)\n    rouge_scores = rouge_metric.compute(\n        predictions=[p.strip() for p in val_preds],\n        references=[r.strip() for r in val_refs],\n        use_stemmer=True\n    )\n    print(f\"[RL] Epoch {epoch+1} Validation Metrics:\")\n    for key, value in rouge_scores.items():\n        if isinstance(value, dict) and 'mid' in value:\n            score = value['mid'].fmeasure * 100\n        else:\n            score = value * 100\n        print(f\"  {key}: {score:.2f}\")\n    avg_hq = sum(hq_scores) / len(hq_scores) if hq_scores else 0.0\n    perc_hq = sum(1 for s in hq_scores if s > 0.5) / len(hq_scores) * 100 if hq_scores else 0.0\n    print(f\"  Average critic high-quality probability: {avg_hq:.3f}\")\n    print(f\"  Percentage high-quality (prob>0.5): {perc_hq:.2f}%\")\n    actor_model.train()\n\n# -------------------------------\n# 11. Final Evaluation After RL Training\n# -------------------------------\nprint(\"\\nFinal evaluation after RL refinement...\")\nactor_model.eval()\nrouge_metric = evaluate.load(\"rouge\")\nval_preds = []\nval_refs = []\nhq_scores = []\nfor batch in actor_val_loader:\n    input_ids = batch[\"input_ids\"].to(device)\n    attn = batch[\"attention_mask\"].to(device)\n    with torch.no_grad():\n        gen_outputs = actor_model.generate(\n            input_ids=input_ids,\n            attention_mask=attn,\n            max_length=128,\n            num_beams=4,\n            num_return_sequences=1\n        )\n    for i, output_ids in enumerate(gen_outputs):\n        gen_text = actor_tokenizer.decode(output_ids, skip_special_tokens=True)\n        cs_text = gen_text.split(\"Rationale:\")[0].strip() if \"Rationale:\" in gen_text else gen_text\n        val_preds.append(cs_text)\n        ref_text = actor_tokenizer.decode(\n            batch[\"labels\"][i][batch[\"labels\"][i] != -100],\n            skip_special_tokens=True\n        )\n        ref_text = ref_text.split(\"Rationale:\")[0].strip() if \"Rationale:\" in ref_text else ref_text\n        val_refs.append(ref_text)\n        hs_text = actor_tokenizer.decode(batch[\"input_ids\"][i], skip_special_tokens=True)\n        if \": \" in hs_text:\n            _, hs_only = hs_text.split(\": \", 1)\n        else:\n            hs_only = hs_text\n        with torch.no_grad():\n            enc = critic_tokenizer(\n                hs_only,\n                cs_text,\n                truncation=True,\n                padding=True,\n                return_tensors=\"pt\",\n                max_length=128\n            )\n            enc_input_ids = enc[\"input_ids\"].to(device)\n            enc_attn = enc[\"attention_mask\"].to(device)\n            logits = critic_model(enc_input_ids, attention_mask=enc_attn).logits\n            prob = F.softmax(logits, dim=-1)[0, 1].item()\n        hq_scores.append(prob)\nresults = rouge_metric.compute(\n    predictions=[p.strip() for p in val_preds],\n    references=[r.strip() for r in val_refs],\n    use_stemmer=True\n)\nprint(\"Final Validation ROUGE scores (after RL):\")\nfor key, value in results.items():\n    if isinstance(value, dict) and 'mid' in value:\n        score = value['mid'].fmeasure * 100\n    else:\n        score = value * 100\n    print(f\"  {key}: {score:.2f}\")\navg_hq = sum(hq_scores) / len(hq_scores) if hq_scores else 0.0\nperc_hq = sum(1 for s in hq_scores if s > 0.5) / len(hq_scores) * 100 if hq_scores else 0.0\nprint(f\"Final Average critic high-quality probability: {avg_hq:.3f}\")\nprint(f\"Final Percentage of high-quality outputs: {perc_hq:.2f}%\")\n\n# -------------------------------\n# 12. Sample Outputs on Test Set\n# -------------------------------\nif raw_test:\n    print(\"\\nSample outputs on test set:\")\n    actor_model.eval()\n    test_loader = DataLoader(actor_test_ds, batch_size=1, shuffle=True)\n    for i, batch in enumerate(test_loader):\n        if i >= 5:\n            break\n        hs_input_ids = batch[\"input_ids\"].to(device)\n        hs_attn = batch[\"attention_mask\"].to(device)\n        hs_text = actor_tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=True)\n        if \": \" in hs_text:\n            _, hs_only = hs_text.split(\": \", 1)\n        else:\n            hs_only = hs_text\n        with torch.no_grad():\n            output_ids = actor_model.generate(\n                input_ids=hs_input_ids,\n                attention_mask=hs_attn,\n                max_length=128,\n                num_beams=4,\n                num_return_sequences=1\n            )[0]\n        output_text = actor_tokenizer.decode(output_ids, skip_special_tokens=True)\n        print(f\"Hate speech: {hs_only.strip()}\")\n        print(f\"Model response: {output_text.strip()}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T15:45:12.332148Z","iopub.execute_input":"2025-04-15T15:45:12.332483Z"}},"outputs":[{"name":"stderr","text":"2025-04-15 15:45:17.709671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744731917.736095     290 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744731917.743200     290 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nNew Train distribution: ClassLabel(names=['no', 'yes'], id=None)\nNew Val distribution: ClassLabel(names=['no', 'yes'], id=None)\nNew Test distribution: ClassLabel(names=['no', 'yes'], id=None)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45781bba4e34d879f6e17d477ad0e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22ea0aae0924f898321689b26b1546d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16e82b57d42c4d29aa416f0e57d6e623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b7e9395ab84431b21f71b9bcd8520f"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce72182a5004a84a7fc037d45bd28fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4603095c2fb2426190a55de7a4288c7c"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8383 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17177035d5034499a87a8a2ab85fb7e5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2795 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c34dbd88f1ad409da1a580219c96b683"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2795 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b7413ff694422589ca35c4aa284e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8383 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8adf00e6c834fdf8e063f162ae98cc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2795 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33d08dbd8f484e038705ac8642b20c25"}},"metadata":{}},{"name":"stdout","text":"Actor Train Columns: ['input_ids', 'attention_mask', 'labels']\nActor Val Columns: ['input_ids', 'attention_mask', 'labels']\nTraining critic (quality classifier)...\n[Critic] Epoch 1/2 - Average Loss: 0.4653\n[Critic] Epoch 2/2 - Average Loss: 0.3089\n[Critic] Validation Accuracy: 87.91%\n\nTraining actor model (supervised fine-tuning on reference counterspeech)...\n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"[Actor Sup] Epoch 1/2 - Average Loss: 2.2668\n[Actor Sup] Epoch 1 Validation Metrics:\n  rouge1: 21.62\n  rouge2: 5.50\n  rougeL: 16.96\n  rougeLsum: 16.96\n[Actor Sup] Epoch 2/2 - Average Loss: 1.6994\n[Actor Sup] Epoch 2 Validation Metrics:\n  rouge1: 24.96\n  rouge2: 7.20\n  rougeL: 18.61\n  rougeLsum: 18.61\n\nStarting reinforcement learning refinement...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_290/2078562691.py:305: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n/tmp/ipykernel_290/2078562691.py:382: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"[RL] Epoch 1/2 - Average Policy Loss: -0.3663\n[RL] Epoch 1 Validation Metrics:\n  rouge1: 24.96\n  rouge2: 7.20\n  rougeL: 18.61\n  rougeLsum: 18.61\n  Average critic high-quality probability: 0.710\n  Percentage high-quality (prob>0.5): 71.16%\n[RL] Epoch 2/2 - Average Policy Loss: -0.3764\n[RL] Epoch 2 Validation Metrics:\n  rouge1: 24.96\n  rouge2: 7.20\n  rougeL: 18.61\n  rougeLsum: 18.61\n  Average critic high-quality probability: 0.710\n  Percentage high-quality (prob>0.5): 71.16%\n\nFinal evaluation after RL refinement...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}